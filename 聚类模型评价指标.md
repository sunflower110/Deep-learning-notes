# 聚类模型评价

聚类算法的理想结果是同一类别内的点相似度高，而不同类别之间的点相似度低。聚类属于无监督
学习，数据没有标签，为了比较不同聚类模型的好坏，我们也需要一些定量的指标来进行评估。根据是否提供样本的标签信息，相关的指标可以分为以下两大类

1. 外部方法，外部方法指的是从外部提供数据的标签，比如通过专家认为定义类别，或者是本身就是有标签的数据，将标签拿掉之后做聚类

2. 内部方法，内部方法指的是不需要数据的标签，仅仅从聚类效果本身出发，而制定的一些指标
## 外部方法

### 1.纯度（Purity）

    纯度的计算方式如下：
    对于每个簇，找到该簇中出现最频繁的类别（即样本数最多的类别）。
    将该簇中所有样本都标记为该最频繁类别。
    计算所有簇中被正确标记的样本数之和，除以总样本数，得到纯度值。
    纯度的取值范围是[0, 1]，纯度值越高表示聚类结果中的簇越纯净，即样本更倾向于被正确地分配到同一类别中。
### 2.规范化相互信息（ Normalized Mutual Information）

<b>基本概念</b>

* 信息量
   
$$
I=-\log_{2}P
$$

  
    在信息论中，信息量的概念就是类似于意外性的度量。
    当事件的概率较低时，它提供的信息量较大，因为它与我们的预期不一致，具有更大的意外性。
    而当事件的概率较高时，它提供的信息量较小，因为我们已经预期到它的发生。
* 熵(entropy)：
$$

  H(x)=-P\log P
$$

    是衡量一个系统的稳定程度。其实就是一个系统所有变量信息量的期望或者说均值。

* 联合熵(joint entropy)
$$
H(X,Y)=-\sum _{x=X,y=Y} P(x,y)*\log P(X,Y)
$$
    多个联合变量的熵，也就是将熵的定义推广到多变量的范围。

* 条件熵(conditional entropy)
$$
H(Y|X)= \sum _{x\in X}P(x)*H(Y|X=x)=\sum _{x\in X}P(x)*\sum_{y\in Y}P(y|x)*logP(y|x)

$$
    一个随机变量在给定的情况下，系统的熵。
*相对熵(relative entropy)

    也被称作KL散度(Kullback–Leibler divergence)。
    当我们获得了一个变量的概率分布时，一般我们会找一种近似且简单的分布来代替